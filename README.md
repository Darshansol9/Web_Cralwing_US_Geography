# Web_Crawling_US_Geography

This is my first learning tasks about web crawling using Beautiful soup libraries Python.
Big Data Technologies work at NYU Tandon School of Engineering has been acknowledged.<br>

Task is to scrap information about all state names of United States and for each state:<br>
Capture Cities and Towns along with this pin code.<br>

Can be used as Fast retireval look up if anyone interested in knowing the pin code of any city/town to which state it belongs.<br>

Generated 50 individual files for each state to keep the work organized.<br>
Each file has following attributes :<br>
State,City,Town,zipcode

Future Progress:<br>
Merging all data into one dataframe using pandas.<br>
Using multiprocessing to scrap data in multiple request form and not sequencial hit.<br>
Glean more data such as geo-cordinate location using APIs to plot og google maps.<br>

 
